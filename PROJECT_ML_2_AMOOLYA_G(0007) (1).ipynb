{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PROJECT ML- 2- AMOOLYA G(0007)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCdupfjEjpvE"
      },
      "source": [
        "NAME: AMOOLYA G USN: 20202AIE0007 MAIL ID1: AMOOLYA.20202AIE0007@PRESIDENCYUNIVERSITY.IN MAIL ID2: amoolya.g99@gmail.com BRANCH: ARTIFICIAL INTELLIGENCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C59_b4Pj00-"
      },
      "source": [
        "PURPOSE OF PROJECT 2: DIMENSION REDUCTION USING PCA ON THE OBTAINED DATASET FROM RAVDESS DATA FROM THE PREVIOUS PROJECT. BUILDING THE MODEL FOR THE RAVDESS DTATASET AND FINDING OUT THE ACCURACY USING DIFFERENT ALGORITHMS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uxry4510Ar1",
        "outputId": "606140d1-64b1-4762-e863-4ec9d4ab0a0b"
      },
      "source": [
        "#importing libraries \n",
        "import glob\n",
        "import librosa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "#mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB_PuG_DjhDg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysKbpGZkji4m"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "aO_UhaYp0fnA",
        "outputId": "19093d50-23ca-41b7-fadb-2fafaed8b745"
      },
      "source": [
        "#loading the csv file from drive\n",
        "dataset= pd.read_csv(r'/content/drive/MyDrive/amoolya.csv')\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>...</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>Emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.048604</td>\n",
              "      <td>0.046917</td>\n",
              "      <td>0.046224</td>\n",
              "      <td>0.047072</td>\n",
              "      <td>0.049290</td>\n",
              "      <td>0.049873</td>\n",
              "      <td>0.050472</td>\n",
              "      <td>0.048150</td>\n",
              "      <td>0.049686</td>\n",
              "      <td>0.051999</td>\n",
              "      <td>0.051157</td>\n",
              "      <td>0.052178</td>\n",
              "      <td>0.053384</td>\n",
              "      <td>0.051440</td>\n",
              "      <td>0.052336</td>\n",
              "      <td>0.053095</td>\n",
              "      <td>0.053420</td>\n",
              "      <td>0.052964</td>\n",
              "      <td>0.053120</td>\n",
              "      <td>0.053120</td>\n",
              "      <td>0.050847</td>\n",
              "      <td>0.043273</td>\n",
              "      <td>0.039369</td>\n",
              "      <td>0.030132</td>\n",
              "      <td>0.026388</td>\n",
              "      <td>0.027664</td>\n",
              "      <td>0.035403</td>\n",
              "      <td>0.036959</td>\n",
              "      <td>0.034249</td>\n",
              "      <td>0.032359</td>\n",
              "      <td>0.035431</td>\n",
              "      <td>0.031136</td>\n",
              "      <td>0.029000</td>\n",
              "      <td>0.026862</td>\n",
              "      <td>0.027110</td>\n",
              "      <td>0.034301</td>\n",
              "      <td>0.037890</td>\n",
              "      <td>0.036831</td>\n",
              "      <td>0.036139</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035537</td>\n",
              "      <td>0.035676</td>\n",
              "      <td>0.040558</td>\n",
              "      <td>0.041039</td>\n",
              "      <td>0.041515</td>\n",
              "      <td>0.039094</td>\n",
              "      <td>0.038623</td>\n",
              "      <td>0.040432</td>\n",
              "      <td>0.042160</td>\n",
              "      <td>0.045109</td>\n",
              "      <td>0.045647</td>\n",
              "      <td>0.045397</td>\n",
              "      <td>0.045437</td>\n",
              "      <td>0.045018</td>\n",
              "      <td>0.045309</td>\n",
              "      <td>0.044183</td>\n",
              "      <td>0.045046</td>\n",
              "      <td>0.039891</td>\n",
              "      <td>0.027748</td>\n",
              "      <td>0.023320</td>\n",
              "      <td>0.019979</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.012797</td>\n",
              "      <td>0.012528</td>\n",
              "      <td>0.011458</td>\n",
              "      <td>0.015750</td>\n",
              "      <td>0.018857</td>\n",
              "      <td>0.023482</td>\n",
              "      <td>0.032036</td>\n",
              "      <td>0.029649</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>0.035279</td>\n",
              "      <td>0.037167</td>\n",
              "      <td>0.035057</td>\n",
              "      <td>0.035728</td>\n",
              "      <td>0.036286</td>\n",
              "      <td>0.036817</td>\n",
              "      <td>0.039406</td>\n",
              "      <td>0.042504</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070820</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070390</td>\n",
              "      <td>0.069623</td>\n",
              "      <td>0.067248</td>\n",
              "      <td>0.064336</td>\n",
              "      <td>0.049413</td>\n",
              "      <td>0.040677</td>\n",
              "      <td>0.041117</td>\n",
              "      <td>0.045219</td>\n",
              "      <td>0.047681</td>\n",
              "      <td>0.050785</td>\n",
              "      <td>0.047997</td>\n",
              "      <td>0.048105</td>\n",
              "      <td>0.049128</td>\n",
              "      <td>0.051151</td>\n",
              "      <td>0.055581</td>\n",
              "      <td>0.055844</td>\n",
              "      <td>0.052594</td>\n",
              "      <td>0.048667</td>\n",
              "      <td>0.048448</td>\n",
              "      <td>0.049332</td>\n",
              "      <td>0.050532</td>\n",
              "      <td>0.050389</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045532</td>\n",
              "      <td>0.042350</td>\n",
              "      <td>0.044208</td>\n",
              "      <td>0.046423</td>\n",
              "      <td>0.048221</td>\n",
              "      <td>0.050919</td>\n",
              "      <td>0.046996</td>\n",
              "      <td>0.046878</td>\n",
              "      <td>0.052049</td>\n",
              "      <td>0.051617</td>\n",
              "      <td>0.052619</td>\n",
              "      <td>0.053739</td>\n",
              "      <td>0.058828</td>\n",
              "      <td>0.054476</td>\n",
              "      <td>0.051314</td>\n",
              "      <td>0.049794</td>\n",
              "      <td>0.045409</td>\n",
              "      <td>0.046280</td>\n",
              "      <td>0.051760</td>\n",
              "      <td>0.051664</td>\n",
              "      <td>0.049244</td>\n",
              "      <td>0.050256</td>\n",
              "      <td>0.048597</td>\n",
              "      <td>0.052073</td>\n",
              "      <td>0.054853</td>\n",
              "      <td>0.054794</td>\n",
              "      <td>0.055284</td>\n",
              "      <td>0.051647</td>\n",
              "      <td>0.052953</td>\n",
              "      <td>0.054660</td>\n",
              "      <td>0.056156</td>\n",
              "      <td>0.058494</td>\n",
              "      <td>0.059817</td>\n",
              "      <td>0.061482</td>\n",
              "      <td>0.058099</td>\n",
              "      <td>0.060554</td>\n",
              "      <td>0.063959</td>\n",
              "      <td>0.064369</td>\n",
              "      <td>0.062153</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.076304</td>\n",
              "      <td>0.077533</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.072013</td>\n",
              "      <td>0.072427</td>\n",
              "      <td>0.076826</td>\n",
              "      <td>0.067054</td>\n",
              "      <td>0.064041</td>\n",
              "      <td>0.067579</td>\n",
              "      <td>0.068436</td>\n",
              "      <td>0.064690</td>\n",
              "      <td>0.065965</td>\n",
              "      <td>0.064361</td>\n",
              "      <td>0.055440</td>\n",
              "      <td>0.053429</td>\n",
              "      <td>0.051646</td>\n",
              "      <td>0.050762</td>\n",
              "      <td>0.049333</td>\n",
              "      <td>0.046499</td>\n",
              "      <td>0.049047</td>\n",
              "      <td>0.052845</td>\n",
              "      <td>0.056021</td>\n",
              "      <td>0.053898</td>\n",
              "      <td>0.052190</td>\n",
              "      <td>0.052463</td>\n",
              "      <td>0.049915</td>\n",
              "      <td>0.049967</td>\n",
              "      <td>0.052342</td>\n",
              "      <td>0.050594</td>\n",
              "      <td>0.052824</td>\n",
              "      <td>0.054405</td>\n",
              "      <td>0.049366</td>\n",
              "      <td>...</td>\n",
              "      <td>0.052113</td>\n",
              "      <td>0.052081</td>\n",
              "      <td>0.056094</td>\n",
              "      <td>0.052847</td>\n",
              "      <td>0.052353</td>\n",
              "      <td>0.043928</td>\n",
              "      <td>0.041175</td>\n",
              "      <td>0.044363</td>\n",
              "      <td>0.047832</td>\n",
              "      <td>0.053752</td>\n",
              "      <td>0.057722</td>\n",
              "      <td>0.052671</td>\n",
              "      <td>0.049842</td>\n",
              "      <td>0.048263</td>\n",
              "      <td>0.048656</td>\n",
              "      <td>0.050956</td>\n",
              "      <td>0.056565</td>\n",
              "      <td>0.054829</td>\n",
              "      <td>0.050479</td>\n",
              "      <td>0.049118</td>\n",
              "      <td>0.053782</td>\n",
              "      <td>0.056288</td>\n",
              "      <td>0.059511</td>\n",
              "      <td>0.059183</td>\n",
              "      <td>0.061141</td>\n",
              "      <td>0.060678</td>\n",
              "      <td>0.062784</td>\n",
              "      <td>0.064004</td>\n",
              "      <td>0.060744</td>\n",
              "      <td>0.061739</td>\n",
              "      <td>0.067151</td>\n",
              "      <td>0.067728</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>0.072873</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.071827</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077675</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068168</td>\n",
              "      <td>0.066622</td>\n",
              "      <td>0.062703</td>\n",
              "      <td>0.061603</td>\n",
              "      <td>0.060335</td>\n",
              "      <td>0.062645</td>\n",
              "      <td>0.051686</td>\n",
              "      <td>0.045906</td>\n",
              "      <td>0.046529</td>\n",
              "      <td>0.045274</td>\n",
              "      <td>0.047479</td>\n",
              "      <td>0.045697</td>\n",
              "      <td>0.045946</td>\n",
              "      <td>0.047125</td>\n",
              "      <td>0.047197</td>\n",
              "      <td>0.051372</td>\n",
              "      <td>0.049034</td>\n",
              "      <td>0.045247</td>\n",
              "      <td>0.043581</td>\n",
              "      <td>0.042868</td>\n",
              "      <td>0.045395</td>\n",
              "      <td>0.048936</td>\n",
              "      <td>0.048892</td>\n",
              "      <td>0.049722</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041139</td>\n",
              "      <td>0.041319</td>\n",
              "      <td>0.042771</td>\n",
              "      <td>0.046791</td>\n",
              "      <td>0.049619</td>\n",
              "      <td>0.050014</td>\n",
              "      <td>0.050987</td>\n",
              "      <td>0.054079</td>\n",
              "      <td>0.054373</td>\n",
              "      <td>0.052226</td>\n",
              "      <td>0.050344</td>\n",
              "      <td>0.051335</td>\n",
              "      <td>0.048284</td>\n",
              "      <td>0.048583</td>\n",
              "      <td>0.053307</td>\n",
              "      <td>0.051587</td>\n",
              "      <td>0.046417</td>\n",
              "      <td>0.049225</td>\n",
              "      <td>0.051898</td>\n",
              "      <td>0.050398</td>\n",
              "      <td>0.053561</td>\n",
              "      <td>0.054141</td>\n",
              "      <td>0.057025</td>\n",
              "      <td>0.057245</td>\n",
              "      <td>0.058095</td>\n",
              "      <td>0.058611</td>\n",
              "      <td>0.057412</td>\n",
              "      <td>0.056369</td>\n",
              "      <td>0.058307</td>\n",
              "      <td>0.059301</td>\n",
              "      <td>0.059802</td>\n",
              "      <td>0.062534</td>\n",
              "      <td>0.063402</td>\n",
              "      <td>0.064510</td>\n",
              "      <td>0.065389</td>\n",
              "      <td>0.064173</td>\n",
              "      <td>0.065121</td>\n",
              "      <td>0.068654</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073299</td>\n",
              "      <td>0.072838</td>\n",
              "      <td>0.069073</td>\n",
              "      <td>0.070090</td>\n",
              "      <td>0.061194</td>\n",
              "      <td>0.054502</td>\n",
              "      <td>0.057259</td>\n",
              "      <td>0.057319</td>\n",
              "      <td>0.056245</td>\n",
              "      <td>0.055257</td>\n",
              "      <td>0.052835</td>\n",
              "      <td>0.048918</td>\n",
              "      <td>0.052456</td>\n",
              "      <td>0.051311</td>\n",
              "      <td>0.050145</td>\n",
              "      <td>0.048227</td>\n",
              "      <td>0.049272</td>\n",
              "      <td>0.049652</td>\n",
              "      <td>0.047528</td>\n",
              "      <td>0.048320</td>\n",
              "      <td>0.045066</td>\n",
              "      <td>0.038262</td>\n",
              "      <td>0.038456</td>\n",
              "      <td>0.045837</td>\n",
              "      <td>0.041876</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049127</td>\n",
              "      <td>0.049677</td>\n",
              "      <td>0.049290</td>\n",
              "      <td>0.044455</td>\n",
              "      <td>0.044837</td>\n",
              "      <td>0.046969</td>\n",
              "      <td>0.047992</td>\n",
              "      <td>0.050359</td>\n",
              "      <td>0.053768</td>\n",
              "      <td>0.056565</td>\n",
              "      <td>0.050063</td>\n",
              "      <td>0.051621</td>\n",
              "      <td>0.054901</td>\n",
              "      <td>0.051335</td>\n",
              "      <td>0.050307</td>\n",
              "      <td>0.053385</td>\n",
              "      <td>0.061673</td>\n",
              "      <td>0.061441</td>\n",
              "      <td>0.060218</td>\n",
              "      <td>0.060027</td>\n",
              "      <td>0.057427</td>\n",
              "      <td>0.055493</td>\n",
              "      <td>0.058945</td>\n",
              "      <td>0.057099</td>\n",
              "      <td>0.057157</td>\n",
              "      <td>0.061654</td>\n",
              "      <td>0.061076</td>\n",
              "      <td>0.061411</td>\n",
              "      <td>0.061061</td>\n",
              "      <td>0.060559</td>\n",
              "      <td>0.059386</td>\n",
              "      <td>0.062878</td>\n",
              "      <td>0.066598</td>\n",
              "      <td>0.067304</td>\n",
              "      <td>0.065758</td>\n",
              "      <td>0.065102</td>\n",
              "      <td>0.068988</td>\n",
              "      <td>0.069318</td>\n",
              "      <td>0.069510</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>1435</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.069213</td>\n",
              "      <td>0.068854</td>\n",
              "      <td>0.070392</td>\n",
              "      <td>0.071099</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070898</td>\n",
              "      <td>0.069609</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070054</td>\n",
              "      <td>0.062273</td>\n",
              "      <td>0.062433</td>\n",
              "      <td>0.066286</td>\n",
              "      <td>0.061026</td>\n",
              "      <td>0.045400</td>\n",
              "      <td>0.040235</td>\n",
              "      <td>0.040472</td>\n",
              "      <td>0.041080</td>\n",
              "      <td>0.041363</td>\n",
              "      <td>0.039897</td>\n",
              "      <td>0.041972</td>\n",
              "      <td>0.042648</td>\n",
              "      <td>0.041167</td>\n",
              "      <td>0.042103</td>\n",
              "      <td>0.047676</td>\n",
              "      <td>0.052948</td>\n",
              "      <td>0.051790</td>\n",
              "      <td>0.051374</td>\n",
              "      <td>0.052727</td>\n",
              "      <td>0.050091</td>\n",
              "      <td>0.046734</td>\n",
              "      <td>0.044472</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050542</td>\n",
              "      <td>0.051604</td>\n",
              "      <td>0.050986</td>\n",
              "      <td>0.055312</td>\n",
              "      <td>0.057629</td>\n",
              "      <td>0.059731</td>\n",
              "      <td>0.055998</td>\n",
              "      <td>0.051781</td>\n",
              "      <td>0.050536</td>\n",
              "      <td>0.047282</td>\n",
              "      <td>0.046961</td>\n",
              "      <td>0.048855</td>\n",
              "      <td>0.049987</td>\n",
              "      <td>0.049070</td>\n",
              "      <td>0.044872</td>\n",
              "      <td>0.043481</td>\n",
              "      <td>0.048180</td>\n",
              "      <td>0.049433</td>\n",
              "      <td>0.048710</td>\n",
              "      <td>0.048006</td>\n",
              "      <td>0.051943</td>\n",
              "      <td>0.059133</td>\n",
              "      <td>0.058087</td>\n",
              "      <td>0.054415</td>\n",
              "      <td>0.054793</td>\n",
              "      <td>0.053610</td>\n",
              "      <td>0.052139</td>\n",
              "      <td>0.053911</td>\n",
              "      <td>0.053419</td>\n",
              "      <td>0.055354</td>\n",
              "      <td>0.063031</td>\n",
              "      <td>0.067284</td>\n",
              "      <td>0.068882</td>\n",
              "      <td>0.068955</td>\n",
              "      <td>0.063619</td>\n",
              "      <td>0.064569</td>\n",
              "      <td>0.068375</td>\n",
              "      <td>0.068093</td>\n",
              "      <td>0.071235</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>1436</td>\n",
              "      <td>0.039114</td>\n",
              "      <td>0.039403</td>\n",
              "      <td>0.039143</td>\n",
              "      <td>0.040031</td>\n",
              "      <td>0.041478</td>\n",
              "      <td>0.043229</td>\n",
              "      <td>0.040043</td>\n",
              "      <td>0.040225</td>\n",
              "      <td>0.040494</td>\n",
              "      <td>0.044805</td>\n",
              "      <td>0.048478</td>\n",
              "      <td>0.046568</td>\n",
              "      <td>0.034319</td>\n",
              "      <td>0.030025</td>\n",
              "      <td>0.028696</td>\n",
              "      <td>0.022772</td>\n",
              "      <td>0.020604</td>\n",
              "      <td>0.024594</td>\n",
              "      <td>0.022532</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>0.021182</td>\n",
              "      <td>0.023584</td>\n",
              "      <td>0.021953</td>\n",
              "      <td>0.021387</td>\n",
              "      <td>0.011269</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.006795</td>\n",
              "      <td>0.011668</td>\n",
              "      <td>0.016489</td>\n",
              "      <td>0.020391</td>\n",
              "      <td>0.027054</td>\n",
              "      <td>0.028577</td>\n",
              "      <td>0.030457</td>\n",
              "      <td>0.028902</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>0.023820</td>\n",
              "      <td>0.024561</td>\n",
              "      <td>0.023011</td>\n",
              "      <td>0.021714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022338</td>\n",
              "      <td>0.024106</td>\n",
              "      <td>0.022617</td>\n",
              "      <td>0.026199</td>\n",
              "      <td>0.031465</td>\n",
              "      <td>0.034080</td>\n",
              "      <td>0.040194</td>\n",
              "      <td>0.039015</td>\n",
              "      <td>0.038491</td>\n",
              "      <td>0.038030</td>\n",
              "      <td>0.040951</td>\n",
              "      <td>0.038759</td>\n",
              "      <td>0.035285</td>\n",
              "      <td>0.033462</td>\n",
              "      <td>0.032113</td>\n",
              "      <td>0.034729</td>\n",
              "      <td>0.032721</td>\n",
              "      <td>0.037323</td>\n",
              "      <td>0.041343</td>\n",
              "      <td>0.042574</td>\n",
              "      <td>0.049034</td>\n",
              "      <td>0.050084</td>\n",
              "      <td>0.046060</td>\n",
              "      <td>0.044965</td>\n",
              "      <td>0.048083</td>\n",
              "      <td>0.050745</td>\n",
              "      <td>0.029605</td>\n",
              "      <td>0.012465</td>\n",
              "      <td>0.008238</td>\n",
              "      <td>0.010223</td>\n",
              "      <td>0.013618</td>\n",
              "      <td>0.015295</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>0.024355</td>\n",
              "      <td>0.027435</td>\n",
              "      <td>0.025571</td>\n",
              "      <td>0.023143</td>\n",
              "      <td>0.027704</td>\n",
              "      <td>0.031096</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>1437</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060619</td>\n",
              "      <td>0.060783</td>\n",
              "      <td>0.061117</td>\n",
              "      <td>0.059481</td>\n",
              "      <td>0.049447</td>\n",
              "      <td>0.037943</td>\n",
              "      <td>0.035631</td>\n",
              "      <td>0.036806</td>\n",
              "      <td>0.027880</td>\n",
              "      <td>0.024843</td>\n",
              "      <td>0.028630</td>\n",
              "      <td>0.031940</td>\n",
              "      <td>0.030360</td>\n",
              "      <td>0.034167</td>\n",
              "      <td>0.043711</td>\n",
              "      <td>0.040821</td>\n",
              "      <td>0.037427</td>\n",
              "      <td>0.036434</td>\n",
              "      <td>0.040082</td>\n",
              "      <td>0.040517</td>\n",
              "      <td>0.037547</td>\n",
              "      <td>0.036146</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047395</td>\n",
              "      <td>0.048472</td>\n",
              "      <td>0.049535</td>\n",
              "      <td>0.047749</td>\n",
              "      <td>0.044812</td>\n",
              "      <td>0.042521</td>\n",
              "      <td>0.037636</td>\n",
              "      <td>0.036245</td>\n",
              "      <td>0.038366</td>\n",
              "      <td>0.043928</td>\n",
              "      <td>0.047947</td>\n",
              "      <td>0.048906</td>\n",
              "      <td>0.048628</td>\n",
              "      <td>0.053405</td>\n",
              "      <td>0.053521</td>\n",
              "      <td>0.051772</td>\n",
              "      <td>0.049611</td>\n",
              "      <td>0.047473</td>\n",
              "      <td>0.050142</td>\n",
              "      <td>0.053242</td>\n",
              "      <td>0.054223</td>\n",
              "      <td>0.045167</td>\n",
              "      <td>0.043618</td>\n",
              "      <td>0.047745</td>\n",
              "      <td>0.053355</td>\n",
              "      <td>0.048586</td>\n",
              "      <td>0.048438</td>\n",
              "      <td>0.054048</td>\n",
              "      <td>0.053584</td>\n",
              "      <td>0.049268</td>\n",
              "      <td>0.048546</td>\n",
              "      <td>0.048091</td>\n",
              "      <td>0.048508</td>\n",
              "      <td>0.050450</td>\n",
              "      <td>0.046540</td>\n",
              "      <td>0.045264</td>\n",
              "      <td>0.046606</td>\n",
              "      <td>0.048138</td>\n",
              "      <td>0.049165</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>1438</td>\n",
              "      <td>0.046075</td>\n",
              "      <td>0.045399</td>\n",
              "      <td>0.044795</td>\n",
              "      <td>0.046462</td>\n",
              "      <td>0.046342</td>\n",
              "      <td>0.046481</td>\n",
              "      <td>0.046903</td>\n",
              "      <td>0.046993</td>\n",
              "      <td>0.047391</td>\n",
              "      <td>0.047618</td>\n",
              "      <td>0.045186</td>\n",
              "      <td>0.045607</td>\n",
              "      <td>0.043193</td>\n",
              "      <td>0.037127</td>\n",
              "      <td>0.033136</td>\n",
              "      <td>0.034194</td>\n",
              "      <td>0.023592</td>\n",
              "      <td>0.017344</td>\n",
              "      <td>0.014342</td>\n",
              "      <td>0.013585</td>\n",
              "      <td>0.015435</td>\n",
              "      <td>0.021176</td>\n",
              "      <td>0.027569</td>\n",
              "      <td>0.031457</td>\n",
              "      <td>0.032146</td>\n",
              "      <td>0.037001</td>\n",
              "      <td>0.036723</td>\n",
              "      <td>0.038868</td>\n",
              "      <td>0.039145</td>\n",
              "      <td>0.039632</td>\n",
              "      <td>0.039088</td>\n",
              "      <td>0.033394</td>\n",
              "      <td>0.030011</td>\n",
              "      <td>0.031033</td>\n",
              "      <td>0.036869</td>\n",
              "      <td>0.041274</td>\n",
              "      <td>0.038580</td>\n",
              "      <td>0.038022</td>\n",
              "      <td>0.036098</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038742</td>\n",
              "      <td>0.035506</td>\n",
              "      <td>0.035434</td>\n",
              "      <td>0.038242</td>\n",
              "      <td>0.037247</td>\n",
              "      <td>0.036428</td>\n",
              "      <td>0.034616</td>\n",
              "      <td>0.037031</td>\n",
              "      <td>0.035872</td>\n",
              "      <td>0.037688</td>\n",
              "      <td>0.037720</td>\n",
              "      <td>0.037538</td>\n",
              "      <td>0.040268</td>\n",
              "      <td>0.044161</td>\n",
              "      <td>0.045326</td>\n",
              "      <td>0.044131</td>\n",
              "      <td>0.042604</td>\n",
              "      <td>0.033374</td>\n",
              "      <td>0.026676</td>\n",
              "      <td>0.029492</td>\n",
              "      <td>0.033626</td>\n",
              "      <td>0.033331</td>\n",
              "      <td>0.031483</td>\n",
              "      <td>0.027307</td>\n",
              "      <td>0.025095</td>\n",
              "      <td>0.025295</td>\n",
              "      <td>0.027292</td>\n",
              "      <td>0.028139</td>\n",
              "      <td>0.029014</td>\n",
              "      <td>0.035124</td>\n",
              "      <td>0.034848</td>\n",
              "      <td>0.035579</td>\n",
              "      <td>0.033598</td>\n",
              "      <td>0.032590</td>\n",
              "      <td>0.034085</td>\n",
              "      <td>0.037646</td>\n",
              "      <td>0.039342</td>\n",
              "      <td>0.042286</td>\n",
              "      <td>0.040841</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>1439</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067730</td>\n",
              "      <td>0.067382</td>\n",
              "      <td>0.067895</td>\n",
              "      <td>0.061277</td>\n",
              "      <td>0.050293</td>\n",
              "      <td>0.045962</td>\n",
              "      <td>0.046857</td>\n",
              "      <td>0.047440</td>\n",
              "      <td>0.045985</td>\n",
              "      <td>0.044852</td>\n",
              "      <td>0.050592</td>\n",
              "      <td>0.050926</td>\n",
              "      <td>0.055164</td>\n",
              "      <td>0.060334</td>\n",
              "      <td>0.057453</td>\n",
              "      <td>0.054340</td>\n",
              "      <td>0.054423</td>\n",
              "      <td>0.052867</td>\n",
              "      <td>0.049615</td>\n",
              "      <td>0.051163</td>\n",
              "      <td>0.051608</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054444</td>\n",
              "      <td>0.052847</td>\n",
              "      <td>0.051437</td>\n",
              "      <td>0.051828</td>\n",
              "      <td>0.050483</td>\n",
              "      <td>0.044249</td>\n",
              "      <td>0.045700</td>\n",
              "      <td>0.050445</td>\n",
              "      <td>0.050972</td>\n",
              "      <td>0.054266</td>\n",
              "      <td>0.054278</td>\n",
              "      <td>0.051940</td>\n",
              "      <td>0.053106</td>\n",
              "      <td>0.052215</td>\n",
              "      <td>0.049696</td>\n",
              "      <td>0.051961</td>\n",
              "      <td>0.053192</td>\n",
              "      <td>0.051671</td>\n",
              "      <td>0.051878</td>\n",
              "      <td>0.054019</td>\n",
              "      <td>0.058114</td>\n",
              "      <td>0.061759</td>\n",
              "      <td>0.059874</td>\n",
              "      <td>0.060645</td>\n",
              "      <td>0.060747</td>\n",
              "      <td>0.063891</td>\n",
              "      <td>0.065189</td>\n",
              "      <td>0.064513</td>\n",
              "      <td>0.063402</td>\n",
              "      <td>0.067191</td>\n",
              "      <td>0.067678</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067722</td>\n",
              "      <td>0.067028</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows Ã— 107 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0         0         1  ...       103       104  Emotions\n",
              "0              0  0.048604  0.046917  ...  0.039406  0.042504         3\n",
              "1              1  0.070517  0.070517  ...  0.064369  0.062153         4\n",
              "2              2  0.076304  0.077533  ...  0.077675  0.077402         1\n",
              "3              3  0.068178  0.068178  ...  0.068654  0.068178         3\n",
              "4              4  0.073149  0.073149  ...  0.069318  0.069510         2\n",
              "...          ...       ...       ...  ...       ...       ...       ...\n",
              "1435        1435  0.070794  0.070794  ...  0.068093  0.071235         8\n",
              "1436        1436  0.039114  0.039403  ...  0.027704  0.031096         6\n",
              "1437        1437  0.060719  0.060719  ...  0.048138  0.049165         8\n",
              "1438        1438  0.046075  0.045399  ...  0.042286  0.040841         6\n",
              "1439        1439  0.067723  0.067723  ...  0.067723  0.067723         8\n",
              "\n",
              "[1440 rows x 107 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWoyLHIP28Te"
      },
      "source": [
        "#dropping the unnamed: 0 column from the dataset\n",
        "dataset= dataset.drop(['Unnamed: 0'], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "KL9lFi5m3NUr",
        "outputId": "20f06bcc-2b2a-4525-d9c6-d761ef95cb69"
      },
      "source": [
        "#output of the dataset after dropping the unnamed: 0 column\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "      <th>101</th>\n",
              "      <th>102</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>Emotions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.048604</td>\n",
              "      <td>0.046917</td>\n",
              "      <td>0.046224</td>\n",
              "      <td>0.047072</td>\n",
              "      <td>0.049290</td>\n",
              "      <td>0.049873</td>\n",
              "      <td>0.050472</td>\n",
              "      <td>0.048150</td>\n",
              "      <td>0.049686</td>\n",
              "      <td>0.051999</td>\n",
              "      <td>0.051157</td>\n",
              "      <td>0.052178</td>\n",
              "      <td>0.053384</td>\n",
              "      <td>0.051440</td>\n",
              "      <td>0.052336</td>\n",
              "      <td>0.053095</td>\n",
              "      <td>0.053420</td>\n",
              "      <td>0.052964</td>\n",
              "      <td>0.053120</td>\n",
              "      <td>0.053120</td>\n",
              "      <td>0.050847</td>\n",
              "      <td>0.043273</td>\n",
              "      <td>0.039369</td>\n",
              "      <td>0.030132</td>\n",
              "      <td>0.026388</td>\n",
              "      <td>0.027664</td>\n",
              "      <td>0.035403</td>\n",
              "      <td>0.036959</td>\n",
              "      <td>0.034249</td>\n",
              "      <td>0.032359</td>\n",
              "      <td>0.035431</td>\n",
              "      <td>0.031136</td>\n",
              "      <td>0.029000</td>\n",
              "      <td>0.026862</td>\n",
              "      <td>0.027110</td>\n",
              "      <td>0.034301</td>\n",
              "      <td>0.037890</td>\n",
              "      <td>0.036831</td>\n",
              "      <td>0.036139</td>\n",
              "      <td>0.034756</td>\n",
              "      <td>...</td>\n",
              "      <td>0.035537</td>\n",
              "      <td>0.035676</td>\n",
              "      <td>0.040558</td>\n",
              "      <td>0.041039</td>\n",
              "      <td>0.041515</td>\n",
              "      <td>0.039094</td>\n",
              "      <td>0.038623</td>\n",
              "      <td>0.040432</td>\n",
              "      <td>0.042160</td>\n",
              "      <td>0.045109</td>\n",
              "      <td>0.045647</td>\n",
              "      <td>0.045397</td>\n",
              "      <td>0.045437</td>\n",
              "      <td>0.045018</td>\n",
              "      <td>0.045309</td>\n",
              "      <td>0.044183</td>\n",
              "      <td>0.045046</td>\n",
              "      <td>0.039891</td>\n",
              "      <td>0.027748</td>\n",
              "      <td>0.023320</td>\n",
              "      <td>0.019979</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.012797</td>\n",
              "      <td>0.012528</td>\n",
              "      <td>0.011458</td>\n",
              "      <td>0.015750</td>\n",
              "      <td>0.018857</td>\n",
              "      <td>0.023482</td>\n",
              "      <td>0.032036</td>\n",
              "      <td>0.029649</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>0.035279</td>\n",
              "      <td>0.037167</td>\n",
              "      <td>0.035057</td>\n",
              "      <td>0.035728</td>\n",
              "      <td>0.036286</td>\n",
              "      <td>0.036817</td>\n",
              "      <td>0.039406</td>\n",
              "      <td>0.042504</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070820</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.070390</td>\n",
              "      <td>0.069623</td>\n",
              "      <td>0.067248</td>\n",
              "      <td>0.064336</td>\n",
              "      <td>0.049413</td>\n",
              "      <td>0.040677</td>\n",
              "      <td>0.041117</td>\n",
              "      <td>0.045219</td>\n",
              "      <td>0.047681</td>\n",
              "      <td>0.050785</td>\n",
              "      <td>0.047997</td>\n",
              "      <td>0.048105</td>\n",
              "      <td>0.049128</td>\n",
              "      <td>0.051151</td>\n",
              "      <td>0.055581</td>\n",
              "      <td>0.055844</td>\n",
              "      <td>0.052594</td>\n",
              "      <td>0.048667</td>\n",
              "      <td>0.048448</td>\n",
              "      <td>0.049332</td>\n",
              "      <td>0.050532</td>\n",
              "      <td>0.050389</td>\n",
              "      <td>0.052401</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045532</td>\n",
              "      <td>0.042350</td>\n",
              "      <td>0.044208</td>\n",
              "      <td>0.046423</td>\n",
              "      <td>0.048221</td>\n",
              "      <td>0.050919</td>\n",
              "      <td>0.046996</td>\n",
              "      <td>0.046878</td>\n",
              "      <td>0.052049</td>\n",
              "      <td>0.051617</td>\n",
              "      <td>0.052619</td>\n",
              "      <td>0.053739</td>\n",
              "      <td>0.058828</td>\n",
              "      <td>0.054476</td>\n",
              "      <td>0.051314</td>\n",
              "      <td>0.049794</td>\n",
              "      <td>0.045409</td>\n",
              "      <td>0.046280</td>\n",
              "      <td>0.051760</td>\n",
              "      <td>0.051664</td>\n",
              "      <td>0.049244</td>\n",
              "      <td>0.050256</td>\n",
              "      <td>0.048597</td>\n",
              "      <td>0.052073</td>\n",
              "      <td>0.054853</td>\n",
              "      <td>0.054794</td>\n",
              "      <td>0.055284</td>\n",
              "      <td>0.051647</td>\n",
              "      <td>0.052953</td>\n",
              "      <td>0.054660</td>\n",
              "      <td>0.056156</td>\n",
              "      <td>0.058494</td>\n",
              "      <td>0.059817</td>\n",
              "      <td>0.061482</td>\n",
              "      <td>0.058099</td>\n",
              "      <td>0.060554</td>\n",
              "      <td>0.063959</td>\n",
              "      <td>0.064369</td>\n",
              "      <td>0.062153</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.076304</td>\n",
              "      <td>0.077533</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.072013</td>\n",
              "      <td>0.072427</td>\n",
              "      <td>0.076826</td>\n",
              "      <td>0.067054</td>\n",
              "      <td>0.064041</td>\n",
              "      <td>0.067579</td>\n",
              "      <td>0.068436</td>\n",
              "      <td>0.064690</td>\n",
              "      <td>0.065965</td>\n",
              "      <td>0.064361</td>\n",
              "      <td>0.055440</td>\n",
              "      <td>0.053429</td>\n",
              "      <td>0.051646</td>\n",
              "      <td>0.050762</td>\n",
              "      <td>0.049333</td>\n",
              "      <td>0.046499</td>\n",
              "      <td>0.049047</td>\n",
              "      <td>0.052845</td>\n",
              "      <td>0.056021</td>\n",
              "      <td>0.053898</td>\n",
              "      <td>0.052190</td>\n",
              "      <td>0.052463</td>\n",
              "      <td>0.049915</td>\n",
              "      <td>0.049967</td>\n",
              "      <td>0.052342</td>\n",
              "      <td>0.050594</td>\n",
              "      <td>0.052824</td>\n",
              "      <td>0.054405</td>\n",
              "      <td>0.049366</td>\n",
              "      <td>0.050809</td>\n",
              "      <td>...</td>\n",
              "      <td>0.052113</td>\n",
              "      <td>0.052081</td>\n",
              "      <td>0.056094</td>\n",
              "      <td>0.052847</td>\n",
              "      <td>0.052353</td>\n",
              "      <td>0.043928</td>\n",
              "      <td>0.041175</td>\n",
              "      <td>0.044363</td>\n",
              "      <td>0.047832</td>\n",
              "      <td>0.053752</td>\n",
              "      <td>0.057722</td>\n",
              "      <td>0.052671</td>\n",
              "      <td>0.049842</td>\n",
              "      <td>0.048263</td>\n",
              "      <td>0.048656</td>\n",
              "      <td>0.050956</td>\n",
              "      <td>0.056565</td>\n",
              "      <td>0.054829</td>\n",
              "      <td>0.050479</td>\n",
              "      <td>0.049118</td>\n",
              "      <td>0.053782</td>\n",
              "      <td>0.056288</td>\n",
              "      <td>0.059511</td>\n",
              "      <td>0.059183</td>\n",
              "      <td>0.061141</td>\n",
              "      <td>0.060678</td>\n",
              "      <td>0.062784</td>\n",
              "      <td>0.064004</td>\n",
              "      <td>0.060744</td>\n",
              "      <td>0.061739</td>\n",
              "      <td>0.067151</td>\n",
              "      <td>0.067728</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>0.072873</td>\n",
              "      <td>0.068966</td>\n",
              "      <td>0.071827</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>0.077675</td>\n",
              "      <td>0.077402</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>0.068168</td>\n",
              "      <td>0.066622</td>\n",
              "      <td>0.062703</td>\n",
              "      <td>0.061603</td>\n",
              "      <td>0.060335</td>\n",
              "      <td>0.062645</td>\n",
              "      <td>0.051686</td>\n",
              "      <td>0.045906</td>\n",
              "      <td>0.046529</td>\n",
              "      <td>0.045274</td>\n",
              "      <td>0.047479</td>\n",
              "      <td>0.045697</td>\n",
              "      <td>0.045946</td>\n",
              "      <td>0.047125</td>\n",
              "      <td>0.047197</td>\n",
              "      <td>0.051372</td>\n",
              "      <td>0.049034</td>\n",
              "      <td>0.045247</td>\n",
              "      <td>0.043581</td>\n",
              "      <td>0.042868</td>\n",
              "      <td>0.045395</td>\n",
              "      <td>0.048936</td>\n",
              "      <td>0.048892</td>\n",
              "      <td>0.049722</td>\n",
              "      <td>0.049998</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041139</td>\n",
              "      <td>0.041319</td>\n",
              "      <td>0.042771</td>\n",
              "      <td>0.046791</td>\n",
              "      <td>0.049619</td>\n",
              "      <td>0.050014</td>\n",
              "      <td>0.050987</td>\n",
              "      <td>0.054079</td>\n",
              "      <td>0.054373</td>\n",
              "      <td>0.052226</td>\n",
              "      <td>0.050344</td>\n",
              "      <td>0.051335</td>\n",
              "      <td>0.048284</td>\n",
              "      <td>0.048583</td>\n",
              "      <td>0.053307</td>\n",
              "      <td>0.051587</td>\n",
              "      <td>0.046417</td>\n",
              "      <td>0.049225</td>\n",
              "      <td>0.051898</td>\n",
              "      <td>0.050398</td>\n",
              "      <td>0.053561</td>\n",
              "      <td>0.054141</td>\n",
              "      <td>0.057025</td>\n",
              "      <td>0.057245</td>\n",
              "      <td>0.058095</td>\n",
              "      <td>0.058611</td>\n",
              "      <td>0.057412</td>\n",
              "      <td>0.056369</td>\n",
              "      <td>0.058307</td>\n",
              "      <td>0.059301</td>\n",
              "      <td>0.059802</td>\n",
              "      <td>0.062534</td>\n",
              "      <td>0.063402</td>\n",
              "      <td>0.064510</td>\n",
              "      <td>0.065389</td>\n",
              "      <td>0.064173</td>\n",
              "      <td>0.065121</td>\n",
              "      <td>0.068654</td>\n",
              "      <td>0.068178</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073149</td>\n",
              "      <td>0.073299</td>\n",
              "      <td>0.072838</td>\n",
              "      <td>0.069073</td>\n",
              "      <td>0.070090</td>\n",
              "      <td>0.061194</td>\n",
              "      <td>0.054502</td>\n",
              "      <td>0.057259</td>\n",
              "      <td>0.057319</td>\n",
              "      <td>0.056245</td>\n",
              "      <td>0.055257</td>\n",
              "      <td>0.052835</td>\n",
              "      <td>0.048918</td>\n",
              "      <td>0.052456</td>\n",
              "      <td>0.051311</td>\n",
              "      <td>0.050145</td>\n",
              "      <td>0.048227</td>\n",
              "      <td>0.049272</td>\n",
              "      <td>0.049652</td>\n",
              "      <td>0.047528</td>\n",
              "      <td>0.048320</td>\n",
              "      <td>0.045066</td>\n",
              "      <td>0.038262</td>\n",
              "      <td>0.038456</td>\n",
              "      <td>0.045837</td>\n",
              "      <td>0.041876</td>\n",
              "      <td>0.041989</td>\n",
              "      <td>...</td>\n",
              "      <td>0.049127</td>\n",
              "      <td>0.049677</td>\n",
              "      <td>0.049290</td>\n",
              "      <td>0.044455</td>\n",
              "      <td>0.044837</td>\n",
              "      <td>0.046969</td>\n",
              "      <td>0.047992</td>\n",
              "      <td>0.050359</td>\n",
              "      <td>0.053768</td>\n",
              "      <td>0.056565</td>\n",
              "      <td>0.050063</td>\n",
              "      <td>0.051621</td>\n",
              "      <td>0.054901</td>\n",
              "      <td>0.051335</td>\n",
              "      <td>0.050307</td>\n",
              "      <td>0.053385</td>\n",
              "      <td>0.061673</td>\n",
              "      <td>0.061441</td>\n",
              "      <td>0.060218</td>\n",
              "      <td>0.060027</td>\n",
              "      <td>0.057427</td>\n",
              "      <td>0.055493</td>\n",
              "      <td>0.058945</td>\n",
              "      <td>0.057099</td>\n",
              "      <td>0.057157</td>\n",
              "      <td>0.061654</td>\n",
              "      <td>0.061076</td>\n",
              "      <td>0.061411</td>\n",
              "      <td>0.061061</td>\n",
              "      <td>0.060559</td>\n",
              "      <td>0.059386</td>\n",
              "      <td>0.062878</td>\n",
              "      <td>0.066598</td>\n",
              "      <td>0.067304</td>\n",
              "      <td>0.065758</td>\n",
              "      <td>0.065102</td>\n",
              "      <td>0.068988</td>\n",
              "      <td>0.069318</td>\n",
              "      <td>0.069510</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.069213</td>\n",
              "      <td>0.068854</td>\n",
              "      <td>0.070392</td>\n",
              "      <td>0.071099</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070898</td>\n",
              "      <td>0.069609</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070794</td>\n",
              "      <td>0.070054</td>\n",
              "      <td>0.062273</td>\n",
              "      <td>0.062433</td>\n",
              "      <td>0.066286</td>\n",
              "      <td>0.061026</td>\n",
              "      <td>0.045400</td>\n",
              "      <td>0.040235</td>\n",
              "      <td>0.040472</td>\n",
              "      <td>0.041080</td>\n",
              "      <td>0.041363</td>\n",
              "      <td>0.039897</td>\n",
              "      <td>0.041972</td>\n",
              "      <td>0.042648</td>\n",
              "      <td>0.041167</td>\n",
              "      <td>0.042103</td>\n",
              "      <td>0.047676</td>\n",
              "      <td>0.052948</td>\n",
              "      <td>0.051790</td>\n",
              "      <td>0.051374</td>\n",
              "      <td>0.052727</td>\n",
              "      <td>0.050091</td>\n",
              "      <td>0.046734</td>\n",
              "      <td>0.044472</td>\n",
              "      <td>0.042795</td>\n",
              "      <td>...</td>\n",
              "      <td>0.050542</td>\n",
              "      <td>0.051604</td>\n",
              "      <td>0.050986</td>\n",
              "      <td>0.055312</td>\n",
              "      <td>0.057629</td>\n",
              "      <td>0.059731</td>\n",
              "      <td>0.055998</td>\n",
              "      <td>0.051781</td>\n",
              "      <td>0.050536</td>\n",
              "      <td>0.047282</td>\n",
              "      <td>0.046961</td>\n",
              "      <td>0.048855</td>\n",
              "      <td>0.049987</td>\n",
              "      <td>0.049070</td>\n",
              "      <td>0.044872</td>\n",
              "      <td>0.043481</td>\n",
              "      <td>0.048180</td>\n",
              "      <td>0.049433</td>\n",
              "      <td>0.048710</td>\n",
              "      <td>0.048006</td>\n",
              "      <td>0.051943</td>\n",
              "      <td>0.059133</td>\n",
              "      <td>0.058087</td>\n",
              "      <td>0.054415</td>\n",
              "      <td>0.054793</td>\n",
              "      <td>0.053610</td>\n",
              "      <td>0.052139</td>\n",
              "      <td>0.053911</td>\n",
              "      <td>0.053419</td>\n",
              "      <td>0.055354</td>\n",
              "      <td>0.063031</td>\n",
              "      <td>0.067284</td>\n",
              "      <td>0.068882</td>\n",
              "      <td>0.068955</td>\n",
              "      <td>0.063619</td>\n",
              "      <td>0.064569</td>\n",
              "      <td>0.068375</td>\n",
              "      <td>0.068093</td>\n",
              "      <td>0.071235</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>0.039114</td>\n",
              "      <td>0.039403</td>\n",
              "      <td>0.039143</td>\n",
              "      <td>0.040031</td>\n",
              "      <td>0.041478</td>\n",
              "      <td>0.043229</td>\n",
              "      <td>0.040043</td>\n",
              "      <td>0.040225</td>\n",
              "      <td>0.040494</td>\n",
              "      <td>0.044805</td>\n",
              "      <td>0.048478</td>\n",
              "      <td>0.046568</td>\n",
              "      <td>0.034319</td>\n",
              "      <td>0.030025</td>\n",
              "      <td>0.028696</td>\n",
              "      <td>0.022772</td>\n",
              "      <td>0.020604</td>\n",
              "      <td>0.024594</td>\n",
              "      <td>0.022532</td>\n",
              "      <td>0.019178</td>\n",
              "      <td>0.021182</td>\n",
              "      <td>0.023584</td>\n",
              "      <td>0.021953</td>\n",
              "      <td>0.021387</td>\n",
              "      <td>0.011269</td>\n",
              "      <td>0.006900</td>\n",
              "      <td>0.006795</td>\n",
              "      <td>0.011668</td>\n",
              "      <td>0.016489</td>\n",
              "      <td>0.020391</td>\n",
              "      <td>0.027054</td>\n",
              "      <td>0.028577</td>\n",
              "      <td>0.030457</td>\n",
              "      <td>0.028902</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>0.023820</td>\n",
              "      <td>0.024561</td>\n",
              "      <td>0.023011</td>\n",
              "      <td>0.021714</td>\n",
              "      <td>0.026465</td>\n",
              "      <td>...</td>\n",
              "      <td>0.022338</td>\n",
              "      <td>0.024106</td>\n",
              "      <td>0.022617</td>\n",
              "      <td>0.026199</td>\n",
              "      <td>0.031465</td>\n",
              "      <td>0.034080</td>\n",
              "      <td>0.040194</td>\n",
              "      <td>0.039015</td>\n",
              "      <td>0.038491</td>\n",
              "      <td>0.038030</td>\n",
              "      <td>0.040951</td>\n",
              "      <td>0.038759</td>\n",
              "      <td>0.035285</td>\n",
              "      <td>0.033462</td>\n",
              "      <td>0.032113</td>\n",
              "      <td>0.034729</td>\n",
              "      <td>0.032721</td>\n",
              "      <td>0.037323</td>\n",
              "      <td>0.041343</td>\n",
              "      <td>0.042574</td>\n",
              "      <td>0.049034</td>\n",
              "      <td>0.050084</td>\n",
              "      <td>0.046060</td>\n",
              "      <td>0.044965</td>\n",
              "      <td>0.048083</td>\n",
              "      <td>0.050745</td>\n",
              "      <td>0.029605</td>\n",
              "      <td>0.012465</td>\n",
              "      <td>0.008238</td>\n",
              "      <td>0.010223</td>\n",
              "      <td>0.013618</td>\n",
              "      <td>0.015295</td>\n",
              "      <td>0.018630</td>\n",
              "      <td>0.024355</td>\n",
              "      <td>0.027435</td>\n",
              "      <td>0.025571</td>\n",
              "      <td>0.023143</td>\n",
              "      <td>0.027704</td>\n",
              "      <td>0.031096</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.060619</td>\n",
              "      <td>0.060783</td>\n",
              "      <td>0.061117</td>\n",
              "      <td>0.059481</td>\n",
              "      <td>0.049447</td>\n",
              "      <td>0.037943</td>\n",
              "      <td>0.035631</td>\n",
              "      <td>0.036806</td>\n",
              "      <td>0.027880</td>\n",
              "      <td>0.024843</td>\n",
              "      <td>0.028630</td>\n",
              "      <td>0.031940</td>\n",
              "      <td>0.030360</td>\n",
              "      <td>0.034167</td>\n",
              "      <td>0.043711</td>\n",
              "      <td>0.040821</td>\n",
              "      <td>0.037427</td>\n",
              "      <td>0.036434</td>\n",
              "      <td>0.040082</td>\n",
              "      <td>0.040517</td>\n",
              "      <td>0.037547</td>\n",
              "      <td>0.036146</td>\n",
              "      <td>0.039382</td>\n",
              "      <td>...</td>\n",
              "      <td>0.047395</td>\n",
              "      <td>0.048472</td>\n",
              "      <td>0.049535</td>\n",
              "      <td>0.047749</td>\n",
              "      <td>0.044812</td>\n",
              "      <td>0.042521</td>\n",
              "      <td>0.037636</td>\n",
              "      <td>0.036245</td>\n",
              "      <td>0.038366</td>\n",
              "      <td>0.043928</td>\n",
              "      <td>0.047947</td>\n",
              "      <td>0.048906</td>\n",
              "      <td>0.048628</td>\n",
              "      <td>0.053405</td>\n",
              "      <td>0.053521</td>\n",
              "      <td>0.051772</td>\n",
              "      <td>0.049611</td>\n",
              "      <td>0.047473</td>\n",
              "      <td>0.050142</td>\n",
              "      <td>0.053242</td>\n",
              "      <td>0.054223</td>\n",
              "      <td>0.045167</td>\n",
              "      <td>0.043618</td>\n",
              "      <td>0.047745</td>\n",
              "      <td>0.053355</td>\n",
              "      <td>0.048586</td>\n",
              "      <td>0.048438</td>\n",
              "      <td>0.054048</td>\n",
              "      <td>0.053584</td>\n",
              "      <td>0.049268</td>\n",
              "      <td>0.048546</td>\n",
              "      <td>0.048091</td>\n",
              "      <td>0.048508</td>\n",
              "      <td>0.050450</td>\n",
              "      <td>0.046540</td>\n",
              "      <td>0.045264</td>\n",
              "      <td>0.046606</td>\n",
              "      <td>0.048138</td>\n",
              "      <td>0.049165</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>0.046075</td>\n",
              "      <td>0.045399</td>\n",
              "      <td>0.044795</td>\n",
              "      <td>0.046462</td>\n",
              "      <td>0.046342</td>\n",
              "      <td>0.046481</td>\n",
              "      <td>0.046903</td>\n",
              "      <td>0.046993</td>\n",
              "      <td>0.047391</td>\n",
              "      <td>0.047618</td>\n",
              "      <td>0.045186</td>\n",
              "      <td>0.045607</td>\n",
              "      <td>0.043193</td>\n",
              "      <td>0.037127</td>\n",
              "      <td>0.033136</td>\n",
              "      <td>0.034194</td>\n",
              "      <td>0.023592</td>\n",
              "      <td>0.017344</td>\n",
              "      <td>0.014342</td>\n",
              "      <td>0.013585</td>\n",
              "      <td>0.015435</td>\n",
              "      <td>0.021176</td>\n",
              "      <td>0.027569</td>\n",
              "      <td>0.031457</td>\n",
              "      <td>0.032146</td>\n",
              "      <td>0.037001</td>\n",
              "      <td>0.036723</td>\n",
              "      <td>0.038868</td>\n",
              "      <td>0.039145</td>\n",
              "      <td>0.039632</td>\n",
              "      <td>0.039088</td>\n",
              "      <td>0.033394</td>\n",
              "      <td>0.030011</td>\n",
              "      <td>0.031033</td>\n",
              "      <td>0.036869</td>\n",
              "      <td>0.041274</td>\n",
              "      <td>0.038580</td>\n",
              "      <td>0.038022</td>\n",
              "      <td>0.036098</td>\n",
              "      <td>0.040076</td>\n",
              "      <td>...</td>\n",
              "      <td>0.038742</td>\n",
              "      <td>0.035506</td>\n",
              "      <td>0.035434</td>\n",
              "      <td>0.038242</td>\n",
              "      <td>0.037247</td>\n",
              "      <td>0.036428</td>\n",
              "      <td>0.034616</td>\n",
              "      <td>0.037031</td>\n",
              "      <td>0.035872</td>\n",
              "      <td>0.037688</td>\n",
              "      <td>0.037720</td>\n",
              "      <td>0.037538</td>\n",
              "      <td>0.040268</td>\n",
              "      <td>0.044161</td>\n",
              "      <td>0.045326</td>\n",
              "      <td>0.044131</td>\n",
              "      <td>0.042604</td>\n",
              "      <td>0.033374</td>\n",
              "      <td>0.026676</td>\n",
              "      <td>0.029492</td>\n",
              "      <td>0.033626</td>\n",
              "      <td>0.033331</td>\n",
              "      <td>0.031483</td>\n",
              "      <td>0.027307</td>\n",
              "      <td>0.025095</td>\n",
              "      <td>0.025295</td>\n",
              "      <td>0.027292</td>\n",
              "      <td>0.028139</td>\n",
              "      <td>0.029014</td>\n",
              "      <td>0.035124</td>\n",
              "      <td>0.034848</td>\n",
              "      <td>0.035579</td>\n",
              "      <td>0.033598</td>\n",
              "      <td>0.032590</td>\n",
              "      <td>0.034085</td>\n",
              "      <td>0.037646</td>\n",
              "      <td>0.039342</td>\n",
              "      <td>0.042286</td>\n",
              "      <td>0.040841</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067730</td>\n",
              "      <td>0.067382</td>\n",
              "      <td>0.067895</td>\n",
              "      <td>0.061277</td>\n",
              "      <td>0.050293</td>\n",
              "      <td>0.045962</td>\n",
              "      <td>0.046857</td>\n",
              "      <td>0.047440</td>\n",
              "      <td>0.045985</td>\n",
              "      <td>0.044852</td>\n",
              "      <td>0.050592</td>\n",
              "      <td>0.050926</td>\n",
              "      <td>0.055164</td>\n",
              "      <td>0.060334</td>\n",
              "      <td>0.057453</td>\n",
              "      <td>0.054340</td>\n",
              "      <td>0.054423</td>\n",
              "      <td>0.052867</td>\n",
              "      <td>0.049615</td>\n",
              "      <td>0.051163</td>\n",
              "      <td>0.051608</td>\n",
              "      <td>0.049030</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054444</td>\n",
              "      <td>0.052847</td>\n",
              "      <td>0.051437</td>\n",
              "      <td>0.051828</td>\n",
              "      <td>0.050483</td>\n",
              "      <td>0.044249</td>\n",
              "      <td>0.045700</td>\n",
              "      <td>0.050445</td>\n",
              "      <td>0.050972</td>\n",
              "      <td>0.054266</td>\n",
              "      <td>0.054278</td>\n",
              "      <td>0.051940</td>\n",
              "      <td>0.053106</td>\n",
              "      <td>0.052215</td>\n",
              "      <td>0.049696</td>\n",
              "      <td>0.051961</td>\n",
              "      <td>0.053192</td>\n",
              "      <td>0.051671</td>\n",
              "      <td>0.051878</td>\n",
              "      <td>0.054019</td>\n",
              "      <td>0.058114</td>\n",
              "      <td>0.061759</td>\n",
              "      <td>0.059874</td>\n",
              "      <td>0.060645</td>\n",
              "      <td>0.060747</td>\n",
              "      <td>0.063891</td>\n",
              "      <td>0.065189</td>\n",
              "      <td>0.064513</td>\n",
              "      <td>0.063402</td>\n",
              "      <td>0.067191</td>\n",
              "      <td>0.067678</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067722</td>\n",
              "      <td>0.067028</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>0.067723</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows Ã— 106 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2  ...       103       104  Emotions\n",
              "0     0.048604  0.046917  0.046224  ...  0.039406  0.042504         3\n",
              "1     0.070517  0.070517  0.070517  ...  0.064369  0.062153         4\n",
              "2     0.076304  0.077533  0.077402  ...  0.077675  0.077402         1\n",
              "3     0.068178  0.068178  0.068178  ...  0.068654  0.068178         3\n",
              "4     0.073149  0.073149  0.073149  ...  0.069318  0.069510         2\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "1435  0.070794  0.070794  0.070794  ...  0.068093  0.071235         8\n",
              "1436  0.039114  0.039403  0.039143  ...  0.027704  0.031096         6\n",
              "1437  0.060719  0.060719  0.060719  ...  0.048138  0.049165         8\n",
              "1438  0.046075  0.045399  0.044795  ...  0.042286  0.040841         6\n",
              "1439  0.067723  0.067723  0.067723  ...  0.067723  0.067723         8\n",
              "\n",
              "[1440 rows x 106 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9dfsr573QVD"
      },
      "source": [
        "#dropping the target column and storing it in a new dataframe\n",
        "#creating a new dataframe that contains only the target column\n",
        "x= dataset.drop('Emotions', 1)\n",
        "y= dataset['Emotions']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-lLjKq9p5DCK"
      },
      "source": [
        "#splitting the dataset to train and test\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=100,test_size=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRUHKuZh5RT7",
        "outputId": "54c1225c-541e-4eea-cdd7-3d481d6bde65"
      },
      "source": [
        "print(x_train)\n",
        "print(x_test)\n",
        "print(y_train)\n",
        "print(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             0         1         2  ...       102       103       104\n",
            "106   0.070148  0.070148  0.070148  ...  0.051540  0.049171  0.049299\n",
            "1288  0.068809  0.068809  0.068809  ...  0.056941  0.057193  0.056501\n",
            "864   0.050915  0.051109  0.050625  ...  0.036652  0.036485  0.038678\n",
            "876   0.043187  0.043548  0.044359  ...  0.046117  0.047317  0.044835\n",
            "420   0.070125  0.070125  0.070125  ...  0.069937  0.065896  0.057982\n",
            "...        ...       ...       ...  ...       ...       ...       ...\n",
            "802   0.056129  0.051813  0.051305  ...  0.066629  0.071785  0.068904\n",
            "53    0.070681  0.070681  0.070681  ...  0.070681  0.070681  0.070681\n",
            "350   0.043454  0.041005  0.041209  ...  0.028207  0.023209  0.021019\n",
            "79    0.044418  0.044389  0.044367  ...  0.033629  0.034112  0.035089\n",
            "792   0.036644  0.037724  0.040619  ...  0.061973  0.059151  0.058128\n",
            "\n",
            "[1008 rows x 105 columns]\n",
            "             0         1         2  ...       102       103       104\n",
            "1320  0.058525  0.058525  0.058560  ...  0.057203  0.057284  0.057264\n",
            "241   0.054896  0.048573  0.046679  ...  0.047161  0.045286  0.043321\n",
            "1203  0.071102  0.071102  0.071102  ...  0.048767  0.044464  0.041764\n",
            "734   0.070421  0.070421  0.070421  ...  0.053739  0.056074  0.061283\n",
            "472   0.057022  0.057011  0.057133  ...  0.048596  0.049298  0.050040\n",
            "...        ...       ...       ...  ...       ...       ...       ...\n",
            "755   0.046782  0.046782  0.046782  ...  0.021099  0.014985  0.010370\n",
            "1055  0.053871  0.051136  0.054532  ...  0.059078  0.060943  0.052587\n",
            "160   0.053658  0.053507  0.052363  ...  0.047471  0.047642  0.048154\n",
            "877   0.051209  0.055044  0.056873  ...  0.048644  0.050221  0.050888\n",
            "542   0.058797  0.053147  0.050106  ...  0.032282  0.033915  0.038214\n",
            "\n",
            "[432 rows x 105 columns]\n",
            "106     6\n",
            "1288    4\n",
            "864     5\n",
            "876     5\n",
            "420     4\n",
            "       ..\n",
            "802     2\n",
            "53      8\n",
            "350     6\n",
            "79      5\n",
            "792     1\n",
            "Name: Emotions, Length: 1008, dtype: int64\n",
            "1320    3\n",
            "241     1\n",
            "1203    2\n",
            "734     7\n",
            "472     7\n",
            "       ..\n",
            "755     6\n",
            "1055    8\n",
            "160     5\n",
            "877     3\n",
            "542     2\n",
            "Name: Emotions, Length: 432, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvI4N6iqB8E1"
      },
      "source": [
        "#principle component analysis for 5 components\n",
        "pca= PCA(n_components= 5)\n",
        "\n",
        "X_train= pca.fit_transform(x_train)\n",
        "X_test= pca.transform(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpFfbPqeGUnD",
        "outputId": "495c4fb9-3866-4b3e-c315-d7a91808072c"
      },
      "source": [
        "#checking the shape of the train dataset without the target column\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1008, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Dwj11CGdDZ"
      },
      "source": [
        "#LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbsbcNT_5jGA",
        "outputId": "7966cbe8-0c20-4f63-a5dc-a4af56a769eb"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Parameters set to their defaults\n",
        "lgr1 = LogisticRegression()\n",
        "\n",
        "\n",
        "#Fit for train data\n",
        "lgr1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD9sK2PQ71bt"
      },
      "source": [
        "#predicting for test dataset\n",
        "y_pred_lg=lgr1.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GBLQ7J37-ty"
      },
      "source": [
        "y_pred = y_pred_lg\n",
        "model  = lgr1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SowqhMh8FRP"
      },
      "source": [
        "#scores for train and test datasets\n",
        "score_train = model.score(X_train, y_train)\n",
        "score_test  = model.score(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkXgavLM8OLt",
        "outputId": "a804ea0c-633a-4978-fec9-6536654cd6cc"
      },
      "source": [
        "#accuracy for train and test\n",
        "print('Accuracy for Train: ', score_train)\n",
        "print('Accuracy for Test: ', score_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for Train:  0.24603174603174602\n",
            "Accuracy for Test:  0.18981481481481483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKXJTqBZPFsL"
      },
      "source": [
        "#confusion matrix for logistic regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 760
        },
        "id": "pdamC2FC8VB9",
        "outputId": "72e49ed1-0390-40da-bb6f-ff7a6e7eec3f"
      },
      "source": [
        "#Metrics\n",
        "from sklearn import metrics\n",
        "\n",
        "#Accuracy ->correct predictions / total number of data points\n",
        "#score_train = model.score(x_train, y_train)\n",
        "#score_test  = model.score(x_test, y_test)\n",
        "\n",
        "print('Accuracy for Train: ', score_train)\n",
        "print('Accuracy for Test: ', score_test)\n",
        "\n",
        "#Confusion Matrix\n",
        "cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "plt.figure(figsize=(9,9))\n",
        "sn.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(score_test)\n",
        "plt.title(all_sample_title, size = 15);\n",
        "\n",
        "FP = cm.sum(axis=0) - np.diag(cm)  \n",
        "FN = cm.sum(axis=1) - np.diag(cm)\n",
        "TP = np.diag(cm)\n",
        "TN = cm.sum() - (FP + FN + TP)\n",
        "\n",
        "# Sensitivity, hit rate, recall, or true positive rate\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP) \n",
        "# Precision or positive predictive value\n",
        "PPV = TP/(TP+FP)\n",
        "# Negative predictive value\n",
        "NPV = TN/(TN+FN)\n",
        "# Fall out or false positive rate\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "# False discovery rate\n",
        "FDR = FP/(TP+FP)\n",
        "\n",
        "print('Correct Classification :', TP.sum())\n",
        "print('Mis- Classifications :', cm.sum() - TP.sum())\n",
        "#01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for Train:  0.24603174603174602\n",
            "Accuracy for Test:  0.18981481481481483\n",
            "[[ 0 26  6  0  3  0  0  0]\n",
            " [ 0 32  9  0  5  0  5  0]\n",
            " [ 0 15  8  0 28  0  1  1]\n",
            " [ 0 30 12  0 14  0  2  0]\n",
            " [ 0 11  7  1 32  0  0  0]\n",
            " [ 0 15  9  0 34  0  5  2]\n",
            " [ 0 30  3  1 11  0 10  0]\n",
            " [ 0 31 22  0 11  0  0  0]]\n",
            "Correct Classification : 82\n",
            "Mis- Classifications : 350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: RuntimeWarning: invalid value encountered in true_divide\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nsFKJXrPQfy"
      },
      "source": [
        "DECISION TREE CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW3TrzKhDA69",
        "outputId": "bc87f8b8-3131-4a9b-f515-587e5ae742ed"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier  \n",
        "# Parameters set \n",
        "classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)  \n",
        "#Fit for train data\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcBKnCmSKRyX",
        "outputId": "d3631650-9af5-4d10-9342-eb262651de17"
      },
      "source": [
        "#predicting for train dataset\n",
        "y_pred = classifier.predict(X_train)#Accuracy\n",
        "print('Accuracy Score:', metrics.accuracy_score(y_train,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SocYyK0EDd7",
        "outputId": "c18c31e6-d6bf-40e4-f9fb-4204e0dede36"
      },
      "source": [
        "#predicting accuracy for test dataset\n",
        "y_pred = classifier.predict(X_test)#Accuracy\n",
        "print('Accuracy Score:', metrics.accuracy_score(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score: 0.18287037037037038\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI6zGZUQPw7X"
      },
      "source": [
        "RANDOM FOREST CLASSIFIER ALGORITHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inEc6a4_K-VR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3617ea97-8eb0-4f67-90ef-4bfa9fe0ca9f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  \n",
        "# Parameters set \n",
        "classifier= RandomForestClassifier(n_estimators= 10, criterion=\"entropy\") \n",
        "#fit for train data \n",
        "classifier.fit(X_train, y_train)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='entropy', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEl1VJblNVxE"
      },
      "source": [
        "#preidcting for test data\n",
        "y_pred= classifier.predict(X_test)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26D-oSI-Nc7u",
        "outputId": "9c8d3455-bc21-4962-a9a4-ee701ae01a6e"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "#outcomes for test data\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4 13  7  4  1  1  3  2]\n",
            " [ 6 21  6  4  2  2  7  3]\n",
            " [ 6  4  9  5 12  8  6  3]\n",
            " [ 6  6  6 14  5 11  4  6]\n",
            " [ 2  5  8  2 19  7  4  4]\n",
            " [ 0  6 17  4 21  8  6  3]\n",
            " [ 0 10  6 12  9  3 13  2]\n",
            " [ 6  2 16  6  3  8  8 15]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.13      0.11      0.12        35\n",
            "           2       0.31      0.41      0.36        51\n",
            "           3       0.12      0.17      0.14        53\n",
            "           4       0.27      0.24      0.26        58\n",
            "           5       0.26      0.37      0.31        51\n",
            "           6       0.17      0.12      0.14        65\n",
            "           7       0.25      0.24      0.25        55\n",
            "           8       0.39      0.23      0.29        64\n",
            "\n",
            "    accuracy                           0.24       432\n",
            "   macro avg       0.24      0.24      0.23       432\n",
            "weighted avg       0.25      0.24      0.24       432\n",
            "\n",
            "0.23842592592592593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYLn5DABQLki"
      },
      "source": [
        "XGBOOST CLASSIFIER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTZgqr-NOgVl",
        "outputId": "56967b39-2443-4303-82c7-eae8d6ce0dfe"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "#parameters set to efault\n",
        "model = XGBClassifier()\n",
        "#fit for train data\n",
        "model.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
              "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBXg_kyrOwMq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d587076-c129-482b-9d5e-587cc139fb21"
      },
      "source": [
        "\n",
        "# predict the target on the train dataset\n",
        "predict_train = model.predict(X_train)\n",
        "print('\\nTarget on train data',predict_train) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target on train data [6 4 5 ... 5 5 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VakCpF2FJIfB",
        "outputId": "3aad60c1-dcda-486e-f5e2-c9c7b075c730"
      },
      "source": [
        "# Accuracy Score on train dataset\n",
        "accuracy_train = accuracy_score(y_train,predict_train)\n",
        "print('\\naccuracy_score on train dataset : ', accuracy_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy_score on train dataset :  0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpUtH2DON7DH",
        "outputId": "adad1740-ffab-480b-c343-3f6c71425ac2"
      },
      "source": [
        "print(confusion_matrix(y_train,predict_train))\n",
        "print(classification_report(y_train,predict_train))\n",
        "print(accuracy_score(y_train, predict_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 31   7   3  14   0   0   4   2]\n",
            " [  0 108   8  12   4   1   4   4]\n",
            " [  1   5  89   7  17   4   8   8]\n",
            " [  0  16   6  93   5   2   9   3]\n",
            " [  1   4   7   6 104   2   9   8]\n",
            " [  2   5   9   6  13  74   7  11]\n",
            " [  0  16   6  11  11   1  84   8]\n",
            " [  0   3   6   9  15   0   6  89]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.51      0.65        61\n",
            "           2       0.66      0.77      0.71       141\n",
            "           3       0.66      0.64      0.65       139\n",
            "           4       0.59      0.69      0.64       134\n",
            "           5       0.62      0.74      0.67       141\n",
            "           6       0.88      0.58      0.70       127\n",
            "           7       0.64      0.61      0.63       137\n",
            "           8       0.67      0.70      0.68       128\n",
            "\n",
            "    accuracy                           0.67      1008\n",
            "   macro avg       0.70      0.65      0.67      1008\n",
            "weighted avg       0.68      0.67      0.67      1008\n",
            "\n",
            "0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e99dc5i5Jihl",
        "outputId": "2593b394-65db-4f09-8d03-fb99533d35c0"
      },
      "source": [
        "# predict the target on the test dataset\n",
        "predict_test = model.predict(X_test)\n",
        "print('\\nTarget on test data',predict_test) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Target on test data [6 6 2 7 7 2 5 8 3 2 5 4 7 6 7 4 6 5 3 4 3 6 2 8 4 2 5 3 5 5 2 8 2 8 5 8 3\n",
            " 3 2 1 5 5 5 7 5 8 5 7 3 5 3 8 8 3 7 7 6 4 2 7 4 8 7 6 4 5 5 6 6 6 5 3 8 5\n",
            " 2 4 6 8 8 1 3 8 8 2 7 5 3 2 4 3 7 6 7 4 7 5 7 4 2 4 4 4 5 7 8 5 2 5 2 6 3\n",
            " 7 1 4 8 6 2 2 5 3 5 2 8 2 5 6 5 7 4 7 3 8 2 5 6 4 6 5 6 3 2 2 2 2 8 4 7 1\n",
            " 7 7 7 2 5 5 6 7 5 6 2 5 5 7 3 8 7 5 7 7 8 8 2 4 3 3 4 8 5 5 6 3 4 4 4 3 3\n",
            " 7 3 3 7 4 4 6 3 8 4 2 5 5 4 6 8 2 8 7 2 8 4 5 6 5 3 8 3 7 3 7 8 5 4 4 5 3\n",
            " 6 4 8 7 7 6 1 2 6 3 4 8 3 2 3 8 7 4 8 2 8 6 8 3 8 8 2 2 5 4 6 2 5 7 2 7 7\n",
            " 3 4 8 5 5 5 2 4 3 2 5 5 8 5 5 4 7 2 7 3 2 3 5 5 5 5 1 8 2 5 8 1 4 7 8 2 1\n",
            " 2 5 5 2 5 4 8 2 2 4 5 2 3 5 2 2 2 5 3 6 8 4 5 7 8 2 5 2 6 3 4 8 2 5 6 3 4\n",
            " 8 3 7 4 6 6 8 7 4 7 4 8 2 5 2 2 8 2 7 3 4 4 4 7 2 8 8 7 5 2 7 7 4 8 3 5 6\n",
            " 4 7 4 8 4 2 2 5 6 6 5 6 5 2 4 2 1 8 8 3 6 1 7 8 7 5 5 3 6 8 8 2 7 5 4 5 6\n",
            " 3 5 6 4 6 1 6 8 6 8 8 2 7 4 8 4 5 6 3 3 5 1 4 3 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9i_UnUhJr3O",
        "outputId": "e3b07772-44dc-49a2-c5f4-fdb9acb77cf8"
      },
      "source": [
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(y_test,predict_test)\n",
        "print('\\naccuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy_score on test dataset :  0.2638888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLVtXMn3OEb_",
        "outputId": "8c03fff4-f5df-4d44-b938-abdfdf7191bc"
      },
      "source": [
        "print(confusion_matrix(y_test,predict_test))\n",
        "print(classification_report(y_test,predict_test))\n",
        "print(accuracy_score(y_test, predict_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2  9  2  3  3  2  5  9]\n",
            " [ 0 23  9  6  3  3  7  0]\n",
            " [ 0  2  7 10 13  5 11  5]\n",
            " [ 4  8  3 16  6  9  6  6]\n",
            " [ 1  1  3  6 22  5  4  9]\n",
            " [ 0  7  7  5 20 11  5 10]\n",
            " [ 0 10  7 10  5  6 13  4]\n",
            " [ 5  6 13  3  6  6  5 20]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.17      0.06      0.09        35\n",
            "           2       0.35      0.45      0.39        51\n",
            "           3       0.14      0.13      0.13        53\n",
            "           4       0.27      0.28      0.27        58\n",
            "           5       0.28      0.43      0.34        51\n",
            "           6       0.23      0.17      0.20        65\n",
            "           7       0.23      0.24      0.23        55\n",
            "           8       0.32      0.31      0.31        64\n",
            "\n",
            "    accuracy                           0.26       432\n",
            "   macro avg       0.25      0.26      0.25       432\n",
            "weighted avg       0.25      0.26      0.25       432\n",
            "\n",
            "0.2638888888888889\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_5TqSbzWWk1"
      },
      "source": [
        "GAUSSIAN NB ALGORITHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFswmRHpJ3_n"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb= GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred= nb.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQgHQXQgLqC8",
        "outputId": "a06186ec-e844-4e60-d2ec-cbc36aea54b7"
      },
      "source": [
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(y_test,y_pred)\n",
        "print('\\naccuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy_score on test dataset :  0.2361111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQgjNUHxOJmQ",
        "outputId": "ddc1a832-64ca-4bf3-e847-28d9830e3b6f"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 4 15  3  7  0  0  4  2]\n",
            " [ 2 26  5  5  1  2 10  0]\n",
            " [ 3  8 13  6 11  4  6  2]\n",
            " [ 3 19  7  8  6  5  7  3]\n",
            " [ 1  4  6  4 19  4  6  7]\n",
            " [ 0  4  8 11 21  4 11  6]\n",
            " [ 2 19  5  9  2  1 14  3]\n",
            " [12  9 11 10  4  3  1 14]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.15      0.11      0.13        35\n",
            "           2       0.25      0.51      0.34        51\n",
            "           3       0.22      0.25      0.23        53\n",
            "           4       0.13      0.14      0.14        58\n",
            "           5       0.30      0.37      0.33        51\n",
            "           6       0.17      0.06      0.09        65\n",
            "           7       0.24      0.25      0.25        55\n",
            "           8       0.38      0.22      0.28        64\n",
            "\n",
            "    accuracy                           0.24       432\n",
            "   macro avg       0.23      0.24      0.22       432\n",
            "weighted avg       0.23      0.24      0.22       432\n",
            "\n",
            "0.2361111111111111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyFUXwNIRn4C"
      },
      "source": [
        "SGD CLASSIFIER ALGORITHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-AXJOAULze_"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "#parameters set\n",
        "sgd= SGDClassifier()\n",
        "#fir for train data\n",
        "sgd.fit(X_train, y_train)\n",
        "#predict on test data\n",
        "y_pred= sgd.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSU2X6v8MUWq",
        "outputId": "0b9eed00-2a08-4eb6-f8c4-cf07fff9f419"
      },
      "source": [
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(y_test,y_pred)\n",
        "print('\\naccuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy_score on test dataset :  0.1712962962962963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrpQtPf1ONEp",
        "outputId": "63e11d3d-da3e-46c6-8723-faaa7f7d0464"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 7 25  0  0  0  0  3  0]\n",
            " [ 1 41  0  0  1  1  7  0]\n",
            " [ 3 27  0  0 12  1  8  2]\n",
            " [ 9 36  0  0  7  2  4  0]\n",
            " [ 4 18  0  0 14  2  8  5]\n",
            " [ 6 24  0  0 18  4  6  7]\n",
            " [ 3 41  0  0  2  0  8  1]\n",
            " [18 30  0  0  3  1 12  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.14      0.20      0.16        35\n",
            "           2       0.17      0.80      0.28        51\n",
            "           3       0.00      0.00      0.00        53\n",
            "           4       0.00      0.00      0.00        58\n",
            "           5       0.25      0.27      0.26        51\n",
            "           6       0.36      0.06      0.11        65\n",
            "           7       0.14      0.15      0.14        55\n",
            "           8       0.00      0.00      0.00        64\n",
            "\n",
            "    accuracy                           0.17       432\n",
            "   macro avg       0.13      0.19      0.12       432\n",
            "weighted avg       0.13      0.17      0.11       432\n",
            "\n",
            "0.1712962962962963\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql6ob5xrR7pT"
      },
      "source": [
        "K NEAREST NEIGHBORS(KNN) ALGORITHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5pdcKEeMW2o"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#parameters set to default\n",
        "knn= KNeighborsClassifier()\n",
        "#fit for train data\n",
        "knn.fit(X_train, y_train)\n",
        "#predict for test data\n",
        "y_pred= knn.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iY3pFCfdMy82",
        "outputId": "8aa518ea-206d-4733-b894-4854cd1c5f19"
      },
      "source": [
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(y_test,y_pred)\n",
        "print('\\naccuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy_score on test dataset :  0.22916666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZG6D5lstOQ5F",
        "outputId": "e66c2961-8400-4bc3-905a-f23ed0323d31"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 5 10  4  5  1  3  5  2]\n",
            " [ 4 29  6  6  3  1  2  0]\n",
            " [ 7  5 10  2 10  7  6  6]\n",
            " [ 8  9  5  7  7 10  7  5]\n",
            " [ 3  7 10  1 15  9  5  1]\n",
            " [ 2  6 14  6 19  8  5  5]\n",
            " [ 6  9  8  8  7  1 14  2]\n",
            " [13  4 15  7  4  6  4 11]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.10      0.14      0.12        35\n",
            "           2       0.37      0.57      0.45        51\n",
            "           3       0.14      0.19      0.16        53\n",
            "           4       0.17      0.12      0.14        58\n",
            "           5       0.23      0.29      0.26        51\n",
            "           6       0.18      0.12      0.15        65\n",
            "           7       0.29      0.25      0.27        55\n",
            "           8       0.34      0.17      0.23        64\n",
            "\n",
            "    accuracy                           0.23       432\n",
            "   macro avg       0.23      0.23      0.22       432\n",
            "weighted avg       0.23      0.23      0.22       432\n",
            "\n",
            "0.22916666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7ARoBdOSSUq"
      },
      "source": [
        "SUPPORT VECTOR MACHINE (SVM) ALGORITHM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgzMCRb8M2fS"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "#parameters set to default\n",
        "svm= SVC()\n",
        "#fit for train data\n",
        "svm.fit(X_train, y_train)\n",
        "#predict for test data\n",
        "y_pred= svm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skBtebzDNT-B",
        "outputId": "88a7b18c-cc7c-4481-d631-7ada82187d7c"
      },
      "source": [
        "# Accuracy Score on test dataset\n",
        "accuracy_test = accuracy_score(y_test,y_pred)\n",
        "print('\\naccuracy_score on test dataset : ', accuracy_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "accuracy_score on test dataset :  0.27546296296296297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b3fEsDeNbrE",
        "outputId": "ec11b11e-189f-4c57-9124-fe328b641ed5"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "print(accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1 11  5  9  1  0  3  5]\n",
            " [ 1 21  9  9  2  1  7  1]\n",
            " [ 0  2 13  9 15  3  4  7]\n",
            " [ 1 10  6 13  8  4 11  5]\n",
            " [ 1  0  3  5 27  2  6  7]\n",
            " [ 0  1 10  6 23  6 10  9]\n",
            " [ 0  7  5 11  5  1 19  7]\n",
            " [ 4  2 20  8  6  2  3 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.12      0.03      0.05        35\n",
            "           2       0.39      0.41      0.40        51\n",
            "           3       0.18      0.25      0.21        53\n",
            "           4       0.19      0.22      0.20        58\n",
            "           5       0.31      0.53      0.39        51\n",
            "           6       0.32      0.09      0.14        65\n",
            "           7       0.30      0.35      0.32        55\n",
            "           8       0.32      0.30      0.31        64\n",
            "\n",
            "    accuracy                           0.28       432\n",
            "   macro avg       0.27      0.27      0.25       432\n",
            "weighted avg       0.27      0.28      0.26       432\n",
            "\n",
            "0.27546296296296297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v00pwuQQn3l2"
      },
      "source": [
        "CONCLUDING BY SAYING WE GOT THE HIGHEST TEST ACCURACY SCORE OF 27.54% USING SVM AND SECOND HIGHEST OF 26.38% USING XGBOOST CLASSIFIER ALGORITHM. IN SVM, WE COULD SEE THAT THERE WERE 119 CORRECT CLASSIFICATION AND THE 4TH EMOTION I.E, SAD IS DETECTED THE MOST CORRECTLY."
      ]
    }
  ]
}